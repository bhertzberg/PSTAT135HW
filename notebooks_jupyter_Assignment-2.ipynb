{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Due date/time: February 13, 2023 at 11:59 PM\n",
    "## Submit Jupyter notebook to class Gradescope\n",
    "\n",
    "Variable `data` shows where data is located. Modify it as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"gs://pstat135-bh/notebooks/jupyter/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016. The data was taken from Kaggle. The `athlete_events` Dataset contains $271,116$ rows and $15$ columns and the NOC region dataset contains $230$ rows and $3$ columns. They will be merged together by the National Olympic Committee (NOC) region. Both files are comma separated.\n",
    "\n",
    "**Source:**\n",
    "\n",
    "Griffin, R, H (2018) 120 years of Olympic history: athletes and results, athlete_events, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#athlete_events.csv\n",
    "\n",
    "Griffin, R, H (2018) 120 years of Olympic history: athletes and results, noc_regions, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#noc_regions.csv\n",
    "\n",
    "**ATTRIBUTES:**\n",
    "\n",
    "**athlete_events.csv**\n",
    "\n",
    "| Column Name | Data Type | Description/Notes |\n",
    "|:----:|:----:|:----|\n",
    "| ID |  integer | Unique number for each athlete |\n",
    "| Name | string | Athleteâ€™s name |\n",
    "| Sex | string | M or F |\n",
    "| Age | integer |  |\n",
    "| Height | integer | In centimeters |\n",
    "| Weight | integer | In kilograms |\n",
    "| Team | string | Team name |\n",
    "| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n",
    "| Games | string | Year and season |\n",
    "| Year | integer |  |\n",
    "| Season | string | Summer or Winter |\n",
    "| City | string | Host city |\n",
    "| Sport | string |  |\n",
    "| Event | string |  |\n",
    "| Medal | string | Gold, Silver, Bronze, or NA |\n",
    "\n",
    "**noc_regions.csv**\n",
    "\n",
    "| Column Name | Data Type | Description/Notes |\n",
    "|:--|--|:--|\n",
    "| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n",
    "| Region | string |  |\n",
    "| notes | string |  |\n",
    "\n",
    "## Upload the data into Google Cloud Storage\n",
    "\n",
    "Use the paths above to download our two files and upload them to your Google bucket. For consistency use the following path:\n",
    "\n",
    "`gs://<BUCKET-NAME>/notebooks/jupyter/data/olympics-analysis`\n",
    "\n",
    "and upload the files into *olympics-analysis* directory.\n",
    "\n",
    "Confirm that files were uploaded successfully and are accessible via the notebook by the following gsutil command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://pstat135-bh/notebooks/jupyter/data/olympics-analysis/athlete_events.csv\n",
      "gs://pstat135-bh/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {data + \"olympics-analysis\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into Spark\n",
    "\n",
    "We can either ask Spark to infer the schema or we explicitely specify it ourselves. For this example we need to specify the schema explicitely since not all the columns will be converted the way we would like to by the default option.\n",
    "\n",
    "As a reminder, here is how we can define a schema contained of two columns, one string and one integer:\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "myManualSchema = StructType([\n",
    "  StructField(\"ID\", LongType(), True),\n",
    "  StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read.format(\"csv\")\\\n",
    "  .schema(myManualSchema)\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"nullValue\", \"NA\")\\\n",
    "  .load(\"gs/path/to/file\")\n",
    "```\n",
    "\n",
    "Modify this code to load athlete_events.csv. Call this DataFrame `athlete_events`:\n",
    "\n",
    "**Note:** We have \"NA\" values in our data. This could cause issues when loading the data. To overcome this we need to let Spark know that what string is representing `null` in the data. We can use the option/parameter `nullValue` (as used in the sample code above) and set it to \"NA\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "\n",
    "mySchema1 = StructType([\n",
    "  StructField(\"ID\", LongType(), True),\n",
    "  StructField(\"Name\", StringType(), True),\n",
    "  StructField(\"Sex\", StringType(), True),\n",
    "  StructField(\"Age\", LongType(), True),\n",
    "  StructField(\"Height\", LongType(), True),\n",
    "  StructField(\"Weight\", LongType(), True),\n",
    "  StructField(\"Team\", StringType(), True),\n",
    "  StructField(\"NOC\", StringType(), True),\n",
    "  StructField(\"Games\", StringType(), True),\n",
    "  StructField(\"Year\", LongType(), True),\n",
    "  StructField(\"Season\", StringType(), True),\n",
    "  StructField(\"City\", StringType(), True),\n",
    "  StructField(\"Sport\", StringType(), True),\n",
    "  StructField(\"Event\", StringType(), True),\n",
    "  StructField(\"Medal\", StringType(), True)\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "athlete_events = spark.read.format(\"csv\")\\\n",
    "  .schema(mySchema1)\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"nullValue\", \"NA\")\\\n",
    "  .load(\"gs://pstat135-bh/notebooks/jupyter/data/olympics-analysis/athlete_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the schema of this DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(ID,LongType,true),StructField(Name,StringType,true),StructField(Sex,StringType,true),StructField(Age,LongType,true),StructField(Height,LongType,true),StructField(Weight,LongType,true),StructField(Team,StringType,true),StructField(NOC,StringType,true),StructField(Games,StringType,true),StructField(Year,LongType,true),StructField(Season,StringType,true),StructField(City,StringType,true),StructField(Sport,StringType,true),StructField(Event,StringType,true),StructField(Medal,StringType,true)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_events.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\n",
      "| ID|                Name|Sex|Age|Height|Weight|          Team|NOC|      Games|Year|Season|     City|        Sport|               Event|Medal|\n",
      "+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\n",
      "|  1|           A Dijiang|  M| 24|   180|    80|         China|CHN|1992 Summer|1992|Summer|Barcelona|   Basketball|Basketball Men's ...| null|\n",
      "|  2|            A Lamusi|  M| 23|   170|    60|         China|CHN|2012 Summer|2012|Summer|   London|         Judo|Judo Men's Extra-...| null|\n",
      "|  3| Gunnar Nielsen Aaby|  M| 24|  null|  null|       Denmark|DEN|1920 Summer|1920|Summer|Antwerpen|     Football|Football Men's Fo...| null|\n",
      "|  4|Edgar Lindenau Aabye|  M| 34|  null|  null|Denmark/Sweden|DEN|1900 Summer|1900|Summer|    Paris|   Tug-Of-War|Tug-Of-War Men's ...| Gold|\n",
      "|  5|Christine Jacoba ...|  F| 21|   185|    82|   Netherlands|NED|1988 Winter|1988|Winter|  Calgary|Speed Skating|Speed Skating Wom...| null|\n",
      "+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "athlete_events.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't use the following columns, let's drop them from the DataFrame in a persistent way:\n",
    "\n",
    "* ID\n",
    "* Games\n",
    "* Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_events = athlete_events.drop('ID', 'Games', 'Event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n",
      "|                Name|Sex|Age|Height|Weight|          Team|NOC|Year|Season|     City|        Sport|Medal|\n",
      "+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n",
      "|           A Dijiang|  M| 24|   180|    80|         China|CHN|1992|Summer|Barcelona|   Basketball| null|\n",
      "|            A Lamusi|  M| 23|   170|    60|         China|CHN|2012|Summer|   London|         Judo| null|\n",
      "| Gunnar Nielsen Aaby|  M| 24|  null|  null|       Denmark|DEN|1920|Summer|Antwerpen|     Football| null|\n",
      "|Edgar Lindenau Aabye|  M| 34|  null|  null|Denmark/Sweden|DEN|1900|Summer|    Paris|   Tug-Of-War| Gold|\n",
      "|Christine Jacoba ...|  F| 21|   185|    82|   Netherlands|NED|1988|Winter|  Calgary|Speed Skating| null|\n",
      "+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_events.show(5) # uncomment before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now load noc_regions.csv. Call this DataFrame `noc_regions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema2 = StructType([\n",
    "  StructField(\"NOC\", StringType(), True),\n",
    "  StructField(\"Region\", StringType(), True),\n",
    "  StructField(\"Notes\", StringType(), True),\n",
    "  \n",
    "])\n",
    "\n",
    "noc_regions = spark.read.format(\"csv\")\\\n",
    "  .schema(mySchema2)\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .option(\"nullValue\", \"NA\")\\\n",
    "  .load(\"gs://pstat135-bh/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+\n",
      "|NOC|     Region|               Notes|\n",
      "+---+-----------+--------------------+\n",
      "|AFG|Afghanistan|                null|\n",
      "|AHO|    Curacao|Netherlands Antilles|\n",
      "|ALB|    Albania|                null|\n",
      "|ALG|    Algeria|                null|\n",
      "|AND|    Andorra|                null|\n",
      "+---+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noc_regions.show(5) # uncomment before submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Since we will be using these two DataFrames a lot in this notebook let's `cache()` them to speed up our execution. Caching allows the DataFrame to be loaded and persist in the memory. If we don't use this option, every time we execute an action our DataFrame gets loaded from our Cloud Storage, which is not ideal and will add to our execution time:\n",
    "\n",
    "**Note:** Caching is a lazy transformation. It will happen the first time you execute an action against the DataFrame, not when you cache that DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Sex: string, Age: bigint, Height: bigint, Weight: bigint, Team: string, NOC: string, Year: bigint, Season: string, City: string, Sport: string, Medal: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_events.cache()  # uncomment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[NOC: string, Region: string, Notes: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noc_regions.cache()  # uncomment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "What is the minimum and maximum `year`?\n",
    "\n",
    "**PSTAT 234**: use `agg` to show both minimum and maximum values in a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|min(year)|\n",
      "+---------+\n",
      "|     1896|\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|max(year)|\n",
      "+---------+\n",
      "|     2016|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "athlete_events.select(F.min('year')).show()\n",
    "athlete_events.select(F.max('year')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Is the following statement True or False?\n",
    "\n",
    "> Averag age of female athletes who attended the olympic games after 1990 has raised when compared to the era before then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(age)|\n",
      "+------------------+\n",
      "|22.034368070953438|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|          avg(age)|\n",
      "+------------------+\n",
      "|24.619499568593614|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athlete_events.filter((athlete_events['Year'] <1990) & (athlete_events['Sex'] == 'F')).agg({'age':'avg'}).show() #before 1990\n",
    "athlete_events.filter((athlete_events['Year'] >=1990) & (athlete_events['Sex'] == 'F')).agg({'age':'avg'}).show() #after 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "How many Gold medals were given to men from 1970 to 2000 (including both years)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3186"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_events.filter((athlete_events['Year'] >=1970) & (athlete_events['Year'] <=2000) & (athlete_events['Sex'] == 'M') & (athlete_events['Medal'] == 'Gold')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "How many NOCs attended Summer Olympics 2016 in Rio de Janeiro?\n",
    "\n",
    "NOC stands for National Olympic Committee. Almost equivalent to a country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_events.filter((athlete_events['Year'] == 2016)).select('NOC').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Create two DataFrames, one for the Winter games and one for the Summer games; these DataFrames should include a list of all NOCs that have wone gold medals in the colympics, and their count. Sort these DataFrame by the count in a descending order. Call these DataFrames `winter_gold_count` and `summer_gold_count` respectively. Using these two, answer the following questions:\n",
    "\n",
    "Which country has the highest gold medal count in the Winter Olympics? How about the Summer Olympics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|NOC|count|\n",
      "+---+-----+\n",
      "|CAN|  305|\n",
      "+---+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "+---+-----+\n",
      "|NOC|count|\n",
      "+---+-----+\n",
      "|USA| 2376|\n",
      "+---+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Highest gold medal count in Winter: Canada\n",
    "#Highest gold medal count in Summer: USA\n",
    "\n",
    "from pyspark.sql.functions import desc, col\n",
    "\n",
    "winter_gold_count = athlete_events.filter((athlete_events['Season'] == 'Winter') & (athlete_events['Medal'] == 'Gold')).select('NOC').groupby('NOC').count().sort(col('count').desc())\n",
    "winter_gold_count.show(1)\n",
    "summer_gold_count = athlete_events.filter((athlete_events['Season'] == 'Summer') & (athlete_events['Medal'] == 'Gold')).select('NOC').groupby('NOC').count().sort(col('count').desc())\n",
    "summer_gold_count.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Using the common field `NOC`, merge `summer_gold_count` and `noc_regions` DataFrames.\n",
    "\n",
    "Which region takes the 10th place? This is based on the number of gold medals in all of the Summer Olympics in our dataset.\n",
    "\n",
    "**PSTAT 234**: repeat the same procedure using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|   Region|sum(gold_count)|\n",
      "+---------+---------------+\n",
      "|      USA|           2376|\n",
      "|   Russia|           1220|\n",
      "|  Germany|           1074|\n",
      "|       UK|            635|\n",
      "|    Italy|            518|\n",
      "|   France|            465|\n",
      "|  Hungary|            432|\n",
      "|Australia|            362|\n",
      "|   Sweden|            352|\n",
      "|    China|            335|\n",
      "+---------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your answer goes here\n",
    "merged = summer_gold_count.join(noc_regions, summer_gold_count.NOC == noc_regions.NOC)\n",
    "merged = merged.withColumnRenamed('count','gold_count')\n",
    "merged = merged.groupBy(\"Region\").sum(\"gold_count\")\n",
    "merged.sort(col('sum(gold_count)').desc()).show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}